{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *corpkit*: a Python-based toolkit for working with parsed linguistic corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Daniel McDonald](mailto:mcdonaldd@unimelb.edu.au?Subject=corpkit)\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **SUMMARY:** This *IPython Notebook* demonstrates how to use `corpkit` to investigate a corpus of paragraphs containing the word *risk* in the NYT between 1963 and 2014.\n",
    "\n",
    "## Orientation\n",
    "\n",
    "First, let's import the functions we'll be using to investigate the corpus. These functions are designed for this interrogation, but also have more general use in mind, so you can likely use them on your own corpora.\n",
    "\n",
    "| **Function name** | Purpose                            | |\n",
    "| ----------------- | ---------------------------------- | |\n",
    "| `interrogator()`  | interrogate parsed corpora         | |\n",
    "| `editor()`  | edit interrogations         | |\n",
    "| `plotter()`       | visualise results | |\n",
    "| `conc()`       | concordancing of plaintext, trees or dependencies | |\n",
    "| `quickview()`     | view `interrogator()` results      | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import corpkit\n",
    "from corpkit import interrogator, editor, quickview, plotter, conc\n",
    "# show visualisations inline:\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's set the path to our corpus. If you were using this interface for your own corpora, you would change this to the path to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to unzip nyt files:\n",
    "# gzip -dc data/nyt.tar.gz | tar -xf - -C data\n",
    "# corpus with annual subcorpora\n",
    "annual_trees = 'data/nyt/years' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our main corpus is comprised of paragraphs from *New York Times* articles that contain a risk word, which we have defined by regular expression as `(?i)\\brisk.?\\b`. This includes *low-risk*, or *risk/reward* as single tokens, but excludes *brisk* or *asterisk*.\n",
    "\n",
    "The data comes from a number of sources.\n",
    "\n",
    "* 1963 editions were downloaded from ProQuest Newsstand as PDFs. Optical character recognition and manual processing was used to create a set of 1200 risk sentences.\n",
    "* The 1987--2006 editions were taken from the *NYT Annotated Corpus*.\n",
    "* 2007--2014 editions were downloaded from *ProQuest Newsstand* as HTML.\n",
    "\n",
    "In total, 149,504 documents were processed. The corpus from which the risk corpus was made is over 150 million words in length!\n",
    "\n",
    "The texts have been parsed for part of speech and grammatical structure by [`Stanford CoreNLP*](http://nlp.stanford.edu/software/corenlp.shtml), using *corpkit*'s `build_corpus()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interrogating the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's start by generating some general information about this corpus. First, let's define a query to find every word in the corpus. Run the cell below to define the `allwords_query` variable as the Tregex query to its right.\n",
    "\n",
    "> *When writing Tregex queries or Regular Expressions, remember to always use `r'...'` quotes!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# any token containing letters or numbers (i.e. no punctuation):\n",
    "allwords_query = r'/[A-Za-z0-9]/ !< __' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we perform interrogations with `interrogator()`. Its most important arguments are:\n",
    "\n",
    "1. **path to corpus**\n",
    "2. Tregex **options**:\n",
    "  * **'words'**: return only words\n",
    "  * **'count'**: return a count of matches\n",
    "  * **'tags'**: return only the tag\n",
    "  * **'both'**: return tag and word together\n",
    "3. the **Tregex query**\n",
    "\n",
    "We only need to count tokens, so we can use the **count** option (it's often faster than getting lists of matching tokens). The cell below will run `interrogator()` over each annual subcorpus and count the number of matches for the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allwords = interrogator(annual_trees, 'count', allwords_query) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the interrogation has finished, we can view our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from the allwords results, print the totals\n",
    "print allwords.totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see the query and options that created the results, you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print allwords.query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lists of years and totals are pretty dry. Luckily, we can use the `plotter()` function to visualise our results. At minimum, `plotter()` needs two arguments:\n",
    "\n",
    "1. a title (in quotation marks)\n",
    "2. a list of results to plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotter('Word counts in each subcorpus', allwords.totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So, we can see that the number of words per year varies quite a lot. That's worth keeping in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of risk words in the NYT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's count the total number of risk words. Notice that we are using the `both` flag, instead of the `count`\n",
    "flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# our query:\n",
    "riskwords_query = r'__ < /(?i).?\\brisk.?\\b/' # any risk word and its word class/part of speech\n",
    "# get all risk words and their tags:\n",
    "riskwords = interrogator(annual_trees, 'both', riskwords_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even when do not use the `count` flag, we can access the total number of matches as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotter('Risk words', riskwords.totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, it's hard to tell whether or not these counts are simply because our annual NYT samples are different sizes. To account for this, we can calculate the percentage of parsed words that are risk words. This means combining the two interrogations we have already performed.\n",
    "\n",
    "We can do this by using `editor()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rel_risk = editor(riskwords.results, '%', allwords.totals)\n",
    "plotter('Relative frequency of risk words', rel_risk.totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's more helpful. We can now see some interesting peaks and troughs in the proportion of risk words. We can also see that 1963 contains the highest proportion of risk words. This is because the manual corrector of 1963 OCR entries preserved only the sentence containing risk words, rather than the paragraph.\n",
    "\n",
    "It's often helpful to not plot 1963 results for this reason. To do this, we can add an argument to the `plotter()` call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotter('Relative frequency of risk words', rel_risk.totals.drop('1963'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps we're interested in not only the frequency of risk words, but the frequency of different `kinds` of risk words. We actually already collected this data during our last `interrogator()` query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "riskwords.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rel_riskwords.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have enough data to do some serious plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotter('Risk word / all risk words', rel_riskwords.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing results\n",
    "\n",
    "Results lists can be edited quickly with `editor()`. It has a lot of different options:\n",
    "\n",
    "  | `editor()` argument | Mandatory/default?       |  Use          | Type  |\n",
    "  | :------|:------- |:-------------|:-----|\n",
    "  | `dataframe1` | **mandatory**      | the results you want to edit | `interrogator()` or `editor` output |\n",
    "  | `operation` | '%'      | if using second list, what operation to perform | `'+', '-', '/', '*', '%', 'k', 'd', 'a'` |\n",
    "  | `dataframe2` | False      | Results to comine in some way with `df` | `interrogator()` or `editor` output (usually, a `.totals` branch) |\n",
    "  | `just_subcorpora` | False    |   Subcorpora to keep   |  list |\n",
    "  | `skip_subcorpora` | False    |   Subcorpora to skip   |  list |\n",
    "  | `merge_subcorpora` | False    |   Subcorpora to merge   |  list |\n",
    "  | `new_subcorpus_name` | False    |   name for merged subcorpora   |  index/str |\n",
    "  | `just_entries` | False    |   Entries to keep   |  list |\n",
    "  | `skip_entries` | False    |   Entries to skip   |  list |\n",
    "  | `merge_entries` | False    |   Entries to merge   |  list of words or indices/a regex to match |\n",
    "  | `sort_by` | False    |   sort results   |  str: `'total', 'infreq', 'name', 'increase', 'decrease'` |\n",
    "  | `keep_top` | False    |   Keep only top n results after sorting   |  int |\n",
    "  | `just_totals` | False    |   Collapse all subcorpora, return Series   | bool |\n",
    "  | `projection` | False    |   project smaller subcorpora   |  list of tuples: [`(subcorpus_name, projection_value)]` |\n",
    "  | `**kwargs` | False    |   pass options to *Pandas*' `plot()` function, *Matplotlib*   |  various |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Examples\n",
    "\n",
    "Let's play around with `editor()` on a very simple interrogation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj = '/JJ.?/ < /(?i)\\brisk/'\n",
    "adj_riskwords = interrogator(annual_trees, 'words', adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to edit subcorpora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "editor(adj_riskwords.results, skip_subcorpora = [1963, 1987, 1988]).results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "editor(adj_riskwords.results, just_subcorpora = [1963, 1987, 1988]).results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "editor(adj_riskwords.results, span_subcorpora = [2000, 2010]).results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can edit entries too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quickview(adj_riskwords.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "editor(adj_riskwords.results, just_entries = [2, 5, 6]).results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "editor(adj_riskwords.results, just_entries = ['risky', 'riskier', 'riskiest']).results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# skip any that start with 'r'\n",
    "editor(adj_riskwords.results, skip_entries = r'^r').results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alphabetically\n",
    "editor(adj_riskwords.results, sort_by = 'name').results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# least frequent\n",
    "editor(adj_riskwords.results, sort_by = 'infreq').results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# increasing in frequency\n",
    "editor(adj_riskwords.results, sort_by = 'increase').results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple options\n",
    "\n",
    "It's possible to use many  options at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "editor(adj_riskwords.results, '%', adj_riskwords.totals, span_subcorpora = [1990, 2000], \n",
    "    just_entries = r'^\\(n', merge_entries = r'(nns|nnp)', newname = 'Plural/proper', sort_by = 'name').results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customising visualisations\n",
    "\n",
    "We can use other `plotter()` arguments to customise what our chart shows. `plotter()`'s possible arguments are:\n",
    "\n",
    "| `plotter()` argument | Mandatory/default?       |  Use          | Type  |\n",
    "| :------|:------- |:-------------|:-----|\n",
    "| `title` | **mandatory**      | A title for your plot | string |\n",
    "| `results` | **mandatory**      | the results you want to plot | `interrogator()` or `editor()` output |\n",
    "| `num_to_plot` | 7    | Number of top entries to show     |  int |\n",
    "| `x_label` | False    | custom label for the x-axis     |  str |\n",
    "| `y_label` | False    | custom label for the y-axis     |  str |\n",
    "| `figsize` | (13, 6) | set the size of the figure | tuple: `(length, width)`|\n",
    "| `tex` | `'try'` | use *TeX* to generate image text | boolean |\n",
    "| `style` | `'ggplot'` | use Matplotlib styles | str: `'dark_background'`, `'bmh'`, `'grayscale'`, `'ggplot'`, `'fivethirtyeight'` |\n",
    "| `legend_pos` | `'default'` | legend position | str: `'outside right'` to move legend outside chart |\n",
    "| `show_totals` | `False` | Print totals on legend or plot where possible | str: '`legend`', '`plot`', '`both`', or 'False' |\n",
    "| `save` | `False` | Save to file | `True`: save as `title`.png. str: save as `str` |\n",
    "| `colours` | `'Paired'` | plot colours | str: any of Matpltlib's colormaps |\n",
    "| `cumulative` | `False` | plot entries cumulatively | bool |\n",
    "| `**kwargs` | False | pass other options to Pandas plot/Matplotlib | `rot = 45`, `subplots = True`, `fontsize = 16`, `cumulative = True`, `stacked = True`, etc. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotter('Example', adj_riskwords.results, kind = 'bar', stacked = True, style = 'fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotter('Example 2', adj_riskwords.results, kind = 'area', x_label = 'Period', cumulative = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotter('Example 3', adj_riskwords.results['at-risk'], kind = 'pie', figsize = (9,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotter('Example 4', adj_riskwords.results, kind = 'line', show_totals = 'legend', \n",
    "        black_and_white = True, legend_pos = 'outside right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and so on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Saving and loading results\n",
    "\n",
    "*corpkit* has functions for saving and loading interrogations, edits, concordance lines and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# specify what to save, and a name for the file.\n",
    "from corpkit import save_result, load_result\n",
    "save_result(allwords, 'allwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then load these results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fromfile_allwords = load_result('allwords')\n",
    "fromfile_allwords.totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're in a project directory with saved data, you can also use `load_all_results()` to load every saved interrogation into a dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# r = load_all_results()\n",
    "# r['riskwords'].totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concordancing\n",
    "\n",
    "You can use `conc()` to do concordancing. Its main arguments are:\n",
    "\n",
    "1. A path to corpus or subcorpus\n",
    "2. The kind of search you want to do (`'trees', 'deps', 'plaintext', 'tokens'`)\n",
    "3. The search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# here, we use a subcorpus of politics articles,\n",
    "# rather than the total annual editions.\n",
    "lines = conc('data/nyt/trees/politics/1999', 'trees', r'/JJ.?/ << /(?i).?\\brisk.?\\b/') # adj containing a risk word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set `conc()` to print *n* random concordances with the *random = n* parameter. You can also store the output to a variable for further searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = conc('data/nyt/trees/years/2007', 'trees', r'/VB.?/ < /(?i).?\\brisk.?\\b/', random = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`conc()` takes another argument, window, which alters the amount of co-text appearing either side of the match. The default is 50 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = conc('data/nyt/trees/health/2013', 'trees', r'/VB.?/ << /(?i).?\\brisk.?\\b/', random = 25, window = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`conc()` also allows you to view parse trees. By default, it's false:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = conc('data/nyt/trees/health/2013', 'trees', r'/VB.?/ << /(?i).?\\brisk.?\\b/', \n",
    "             random = 25, window = 20, trees = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More coming soon..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
